---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "What Caused The Early Millenium Slowdown? Evidenece Based on Vector Autoregressions"
subtitle: "A replication of Gert Peersman (2005) paper"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Jessica Van der Berg"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "20190565" # First Author's Affiliation
Email1: "20190565\\@sun.ac.za" # First Author's Email address


keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
  Abstract to be written here. The abstract should not be too long and should provide the reader with a good understanding what you are writing about. Academic papers are not like novels where you keep the reader in suspense. To be effective in getting others to read your paper, be as open and concise about your findings here as possible. Ideally, upon reading your abstract, the reader should feel he / she must read your paper in entirety.
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)


slowdown_dataset <- read.table("~/GitHub/Time-Series/replication/data/slowdown_dataset.txt", quote="\"", comment.char="")

slowdown_dataset <- slowdown_dataset %>% rename(Date = V1, OIL = V2, YEMU = V3, CPEMU = V4, SEMU = V5, YUS= V6, CPUS = V7, SUS = V8) 
slowdown_dataset <- slowdown_dataset[-c(131), ] 

```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction 

In this research assignment, I replicate a research assignment by Gert Peersman (2005), a German economist, titled "What caused the early millennium slowdown? Evidence based on vector autoregressions". In this paper, Peersman (2005) uses a simple four-variable VAR (vector autogressive model) and an identification based scheme based on sign restrictions to examine the effects of a supply, demand, monetary policy and oil price shocks. Peersman (2005) uses data from the United States and Euro area. However, this assignment will only focus on analyzing shocks for the USA. Peersman (2005) concludes that the millennial slowdown is not the result of one particular shock, but a combination of them. The goal of this assignment is to replicate the results of Peersman (2005) as well as preform additional robustness test to ensure the validity of Peermans (2005) results.

- summarize what robustiness checks and analysis you did(including the ones that you replicate)

This paper is structured as follows: The first section will give an overview of the paper with respects to the economics, methodology and data that Peersman (2005) used. The second section will replicate the results for the US. The third section will perform robustness checks and the forth section will conclude.

# Overview of the paper 
## Theory 
## Data 
## Methodology 

# Impulse response function 

First thing I need to do is convert the data to a time series object in R. And to do this I need to create a date column. 

The graph below, just shows you the dataset for the US. This is nice because you can see the pattern all the vaaraibles follow. This is not in the paper but might be nice to put in under 'descriptive statistics'. 

Now that I have a nice little graph, I can continue by creating my VAR. WE first look at a simple four variable VAR. These variables are OIL, CPUS, YUS and SUS. This VAR will then be used for my impulse response functions. 

```{r}

library(vars)
# putting my data in a time series object

us_model <- VAR(ts_us, p=1, type = "const")
summary(us_model)

c <-irf(us_model, impulse.varaible="OIL", response.variable =  "YUS", draw.plot=TRUE, boot=TRUE, n.ahead=20)

plot(c)


```

# Structural VAR 

Argue that authors do no make use of a simple VAR but rather a structural VAR. 

First VAR analysis that Peersman does is based on conventional zero contemporaneous and long run restrictions. Peersman assumes that there is a contemporaneous impact of an oil shock on all other variables in the system, but no immediate impact of the other shocks on oil prices. 
```{r}

library(vars)
# Using data calculated below. 

# Prove that one lag is optimal. 
# We want to get a reduced-form VAR to get an appropriate object that is manipulated into the structural form model 

var1 <- VAR(vardat0, p=1, type="const")

# apply long run restrictions 
model1 <- BQ(var1)
summary(model1)


#impulse response functions 
irf1 <- irf(var1, impulse="oil", response = "S", boot=TRUE, n.ahead =40, ci=0.84, runs=100)


plot(irf1)
```




```{r}
# WE need to set up a matrix for the contemporaneous impact of an oil shock on all other variables. 
vardat0 <- cbind(oil,Y, CP, S)

a.mat <- diag(4)
diag(a.mat) <- NA
a.mat[1,1] <- NA
a.mat[1,2] <- 0
a.mat[1,3] <- 0
a.mat[1,4] <- 0
a.mat[2,1] <- NA
a.mat[2,2] <- NA
a.mat[3,1] <- NA
a.mat[4,1] <- NA
a.mat[2,3] <- NA
a.mat[2,4] <- NA
a.mat[3,2] <- NA
a.mat[3,4] <- 0
a.mat[4,2] <- NA
a.mat[4,3] <- NA
a.mat[4,4] <- NA
a.mat[3,3] <- NA

print(a.mat)

# setting up matrix for the identification of individual shocks. 
b.mat <- diag(4)
diag(b.mat)<- NA
b.mat[1,2] <- NA
b.mat[1,3] <- NA
b.mat[1,4] <- NA
b.mat[2,1] <- NA
b.mat[3,1] <- NA
b.mat[3,2] <- NA
b.mat[3,3] <- NA
b.mat[3,4] <- NA
b.mat[4,1] <- NA
b.mat[4,2] <- NA
b.mat[4,3] <- NA
print(b.mat)
var1 <- VAR(vardat0, p=3, type="const")

svar.one <- SVAR(var1, Amat=a.mat, Bmat=b.mat)
?SVAR


plot(irf(svar.one, impulse = "oil", response = "Y", n.ahead=40, boot=TRUE, ortho=TRUE, ci=0.84))


```
## ACTUAL PROJECT DTAA

```{r}
# Data manipulation. 

y1 = 100*log(as.numeric(slowdown_dataset$YUS))
p1= 100*log(as.numeric(slowdown_dataset$CPUS))
Wp = 100*log(as.numeric(slowdown_dataset$OIL))
s1 <- as.numeric(slowdown_dataset$SUS[-1])

dy1 <- diff(y1)
dp1 <- diff(p1)
dWp <- diff(Wp)

ly <- dy1 - mean(dy1)
lp <- dp1 - mean(dp1)
lw <- dWp - mean(dWp)
ls <- s1 - mean(s1)

Y <- ts(ly , start=c(1970,2), frequency = 4)
CP <- ts(lp , start=c(1970,2), frequency = 4)
oil <- ts(lw , start=c(1970,2), frequency = 4)
S <- ts(ls , start=c(1970,2), frequency = 4)
vardat0 <- cbind(oil,Y, CP, S)

plot.ts(vardat0, main="")

   
```

# Test wether variables are stationary \label{stationary}
 
Variables that are included in the dataset (same order): oil, output growth, consumer inflation and short-term nominal interest rate for EU and US. 

Gideon suggested I only do the replication for the US, since this will be a lot of work. 


In order to test whether a variable is stationary, you can use a unit root test such as the Dickey-Fuller (DF) test

Null hypothesis: There is a unit root 
Alternative hypothesis: Time series is stationary 

If p-values is less than 0.05, it means we can reject the null hypothesis. 

```{r}

library(tseries)
library(ggplot2)
library(dplyr)

detach("package:dplyr", character.only = TRUE)
library("dplyr", character.only = TRUE)

 x <- as.data.frame(vardat0)
adf.test(x$oil)
adf.test(x$Y)
adf.test(x$S)
adf.test(x$CP)

pp.test(x$oil)
pp.test(x$Y)
pp.test(x$S)
pp.test(x$CP)
```


#Optimal lag length

I now determine the optimal lag length for an unrestricted VAR with a maximum lag length of 10.

According to the AIC and the FPE, the optimal lag length is 4. However, the SC and HQ criterion indicates an optimal lag length of 1. The data estimates a VAR including a constant and a trend as deterministic regressor. 

I will use a VAR with lag length eual to one as specified by the paper.

```{r}
library(vars)
detach("package:dplyr", character.only = TRUE)
library("dplyr", character.only = TRUE)

# putting my data in a time series object
lag <- VARselect(vardat0, type="both") 
lag
```


# VAR 

```{r}

# You want to argue here that it is a contant coefficient VAR. Look at replication paper and site. 
plot(VAR(vardat0, p=1, type ="const"))

```
# Diagnostic tests and Test statistics

The results for diagnostic test for VAR(1), VAR(2) and VAR(3) are provided in the table below.

Here you look and interpret all the test to determine whether VAR(1) is too restrictive. ARGUE this as part of your robustness test for the paper. 

```{r}
ser11 <- serial.test(VAR(vardat0, p=1, type ="const"), lags.pt = 16, type ="PT.asymptotic")
ser11$serial

norm1 <- normality.test(VAR(vardat0, p=1, type ="const"))
norm1$jb.mul

arch1 <- arch.test(VAR(vardat0, p=1, type ="const"), lags.multi = 5)
arch1$arch.mul

```

# Short run restrictions 
Contemporaneous parameters

There is a contemporaneous impact of an oil shock on all variables but no immediate impact of other shocks on oil 

monetary policy also has no contemporaneous effect on output.


Therefore b12=b13=b14=0 and b24=0 (found in Gerts discussion paper)

Note restrictions on matrix K2-k/2. This implies we need six restrictions. 
Gert paper gives 4 short run and two long run restrictions. Therefore we need to argue two more short run restrictions. 

b23=0 since monetary policy shocks are shocks with a temporary effect on output, and are a combination of monetary policy, money demand an possibly exchange rate shocks, as longs as these shocks have an influence on short term interest rates  
 Monetary policy has no effect on marcro economic variables (CObin, 2012). Therefore b34=0


```{r}

```


# Conclusion


\newpage

# References {-}

<div id="refs"></div>


# Appendix {-}

## Appendix A {-}

Some appendix information here

## Appendix B {-}

